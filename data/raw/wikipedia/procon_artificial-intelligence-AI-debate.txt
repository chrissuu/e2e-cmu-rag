Artificial intelligence (AI) is the use of “ computers and machines to mimic the problem-solving and decision-making capabilities of the human mind,” according to IBM . [1]
The idea of AI dates back at least 2,700 years. As explained by Adrienne Mayor, research scholar, folklorist, and science historian at Stanford University , “Our ability to imagine artificial intelligence goes back to ancient times. Long before technological advances made self-moving devices possible, ideas about creating artificial life and robots were explored in ancient myths.” [2]
Mayor notes that the myths about Hephaestus , the Greek god of invention and blacksmithing, included precursors to AI. For example, Hephaestus created the giant bronze man Talos, which had a mysterious life force from the gods called ichor . Hephaestus also created Pandora and her infamous and powerful jar/box, as well as a set of automated servants made of gold that were given the knowledge of the gods. Mayor concludes, “Not one of those myths has a good ending once the artificial beings are sent to Earth. It’s almost as if the myths say that it’s great to have these artificial things up in heaven used by the gods. But once they interact with humans, we get chaos and destruction.” [2]
The modern notion of AI largely began when Alan Turing , who contributed to breaking the Nazis’ Enigma code during World War II , created the “ Turing test ” to determine if a computer is capable of “thinking.” The value and legitimacy of the test have long been debated. [1] [3] [4]
The “Father of Artificial Intelligence,” John McCarthy , coined the term “artificial intelligence” as “the science and engineering of making intelligent machines.” He would go on to create the computer programming language LISP (which is still used in AI), host computer chess games against human Russian opponents, and develop the first computer with “hand-eye” capability, all important building blocks for AI. [1] [5] [6] [7]
AI technology continued to grow at a rapid pace during the 1950s. And, as computers became cheaper in the 1960s and ’70s, AI programs flourished, and U.S. government agencies including the Defense Advanced Research Projects Agency (DARPA) began to fund AI-related research. But computers were still too weak to manage the language tasks researchers asked of them. Another influx of funding in the 1980s and early ’90s furthered the research, including the invention of expert systems . But progress again waned with another drop in government funding. [10]
More recently, advances in computer storage limits and speeds have opened new avenues for AI research and implementation, aiding scientific research and forging new paths in medicine for patient diagnosis, robotic surgery, and drug development. [1] [10] [11] [12]
Now, artificial intelligence is used for a variety of everyday implementations including facial recognition software, online shopping algorithms, search engines, digital assistants like Siri and Alexa , translation services, automated safety functions on cars, cybersecurity, airport body scanning security, poker playing strategy, and fighting disinformation on social media .  Generative AI (a kind of AI used in content creation, including text, images, and music) is also widely used for any writing project, from crafting and sending out resumes and sales pitches to completing homework assignments such as essays and book reports. [13] [58]
For more on the history of AI, and for the latest developments in AI, see ProCon’s Historical Timeline .
Pro 1: AI can make everyday life more enjoyable and convenient, while improving our health and standard of living.
Why sit in a traffic jam when a map app can navigate you around the car accident? Why fumble with shopping bags searching for your keys in the dark when a preset location-based command can have your doorway illuminated as you approach your now unlocked door? [23]
Why scroll through hundreds of possible TV shows when the streaming app already knows what genres you like? Why forget eggs at the grocery store when a digital assistant can take an inventory of your refrigerator and add them to your grocery list and have them delivered to your home? All of these marvels are assisted by AI technology. [23]
AI-enabled fitness apps boomed during the COVID-19 pandemic when gyms were closed, increasing the number of AI options for at-home workouts. Now, you can not only set a daily steps goal with encouragement reminders on your smart watch, but you can ride virtually through the countryside on a Peloton bike from your garage or have a personal trainer on your living room TV. For more specialized fitness, AI wearables can monitor yoga poses or golf and baseball swings. [24] [25]
AI can even enhance your doctor’s appointments and medical procedures. It can alert medical caregivers to patterns in your health data as compared to a vast library of medical data, while also doing the paperwork tied to medical appointments so doctors have more time to focus on their patients, resulting in more personalized care. AI can even help surgeons be quicker, more accurate, and less invasive in their operations. [26]
Smart speakers including Amazon’s Echo can use AI to soothe babies to sleep and monitor their breathing. Using AI, speakers can also detect regular and irregular heartbeats, as well as heart attacks and congestive heart failure. [27] [28] [29]
AI is even beginning to excel at creative writing, producing fiction and poetry that some readers enjoy. Some observers predict that TV and film scripts will also soon benefit from the compositional powers of AI.
Pro 2: AI makes work easier for students and professionals alike.
Much like the calculator did not signal the end of students’ grasp of mathematics, typing did not eliminate handwriting, and Google did not herald the end of research skills. AI does not signal the end of reading and writing or of education in general. [78] [79]
Elementary school teacher Shannon Morris explains that AI tools like “ChatGPT can help students by providing real-time answers to their questions, engaging them in personalized conversations, and providing customized content based on their interests. It can also offer personalized learning resources, videos, articles, and interactive activities. This resource can even provide personalized recommendations for studying, help with research, provide context-specific answers, and offer educational games.” She also notes that teachers’ more daunting tasks like grading and making vocabulary lists can be streamlined with AI tools. [79]
For adults AI can similarly make work easier and more efficient, rather than signaling the rise of the robot employee. Pesky, time-consuming tasks like scheduling and managing meetings, finding important emails amongst the spam, prioritizing tasks for the day, and creating and posting social media content can be delegated to AI, freeing up time for more important and rewarding work. The technology can also help with brainstorming, understanding difficult concepts, finding errors in code, and learning languages via conversation, making daunting tasks more manageable. [80]
AI is a tool that, if used responsibly, can enhance both learning and work for everyone. Carri Spector of the Stanford Graduate School of Education says, “I think of AI literacy as being akin to driver’s ed: We’ve got a powerful tool that can be a great asset, but it can also be dangerous. We want students to learn how to use it responsibly.” [81]
Pro 3: AI helps marginalized groups by offering accessibility for people with disabilities.
Artificial intelligence is commonly integrated into smartphones and other household devices. Virtual assistants, including Siri, Alexa, and Cortana, can perform innumerable tasks from making a phone call to navigating the internet. People who are deaf and hearing impaired can access transcripts of voicemail or other audio, for example. [20]
Other virtual assistants can transcribe conversations as they happen, allowing for more comprehension and participation by those who have impairments that affect their communication. Using voice commands with virtual assistants can help people with mobility disabilities who may have difficulty navigating small buttons or screens or turning on a lamp. [20]
Apps enabled by AI on smartphones and other devices, including VoiceOver and TalkBack, can read messages, describe app icons or images, and give information such as battery levels for visually impaired people. Other apps, such as Voiceitt, can transcribe and standardize the voices of people with speech impediments. [20]
Wheelmap provides users with information about wheelchair accessibility, and Evelity offers indoor navigation tools that are customized to the user’s needs, providing audio or text instructions and routes for wheelchair accessibility. [20]
Other AI implementations, such as smart thermostats, smart lighting, and smart plugs, can be automated to work on a schedule to aid people with mobility or cognitive disabilities to lead more independent lives. [21]
More advanced AI projects can combine with robotics to help physically disabled people. HOOBOX Robotics, for example, uses facial recognition software to allow a wheelchair user to move their wheelchair with facial expressions, making movement easier for seniors and those with ALS or quadriparesis . [22]
Pro 4: Artificial intelligence can improve workplace safety.
AI doesn’t get stressed, tired, or sick, three major causes of human accidents in the workplace. AI robots can collaborate with or replace humans for especially dangerous tasks. For example, 50 percent of construction companies that used drones to inspect roofs and other risky tasks saw improvements in safety. [14] [15]
Artificial intelligence can also help humans be safer. For instance, AI can ensure employees are up to date on training by tracking and automatically scheduling safety or other training. AI can also check and offer corrections for ergonomics to prevent repetitive stress injuries or worse. [16]
An AI program called AI-SAFE (Automated Intelligent System for Assuring Safe Working Environments) aims to automate the workplace personal protective equipment (PPE) check, eliminating human errors that could cause accidents in the workplace. As more people wear PPE to prevent the spread of COVID-19 and other viruses, this sort of AI could protect against large-scale outbreaks. [17] [18] [19]
In India, AI was used during the coronavirus pandemic to reopen factories safely by providing camera, cell phone, and smart wearable device-based technology to ensure social distancing, take employee temperatures at regular intervals, and perform contact tracing if anyone tested positive for the virus. [18] [19]
AI can also perform more sensitive tasks in the workplace such as scanning work emails for improper behavior and types of harassment. [15]
Pro 5: AI can function as a reliable research partner.
While AI can be wrong, limited, biased, or misleading, so can every other information source including textbooks, the Internet at large, and people. Whether you’re looking for a new restaurant, writing a college research paper, or trying to cure cancer, the job of any researcher is to distinguish between good and bad information. AI is simply a tool. For example, ChatGPT and Google AI, which now offer citations, are now as reliable as a search engine or a library card catalog in that researchers should go to the primary sources and evaluate the information for themselves. [103]
Leo S. Lo, dean of the College of University Libraries and Learning Sciences at the University of New Mexico, who calls AI "my new favorite research partner," noted, a "limitation of ChatGPT is that it cannot replace critical thinking. Although it can help researchers generate ideas, it cannot replace their ability to critically think about research. In addition, it may not possess the same depth and nuance as a human researcher." As such, AI is simply another research tool. [104]
As a tool, a 2024 study found AI was helpful for academic research in several areas: “idea generation, content structuring, literature synthesis, data management, editing, and ethical compliance.” Note that the list does not include the actual research or writing the paper. Instead, AI is a brainstorming tool that has the entire Internet at it’s disposal, which also lends itself to “literature synthesis” (collating information from multiple sources). AI can also be used to put data in nicely formatted tables and point out where a comma is missing. All of that help leaves researchers time and effort to focus on the actual research component. [105]
The study noted that AI can be especially helpful when researchers need information from another field of study: “AI holds immense potential to revolutionise and streamline interdisciplinary research, acting as a bridge between diverse fields. Its advanced data analysis capabilities enable it to uncover patterns and correlations that might be invisible to human researchers, thereby fostering new insights and theories. AI can process and synthesize vast amounts of information from different disciplines, helping researchers in one field to utilize findings from another, leading to innovative solutions.” Again, AI is “helping” researchers, not running wild in a lab. [105]
When asked if it’s a good research partner, ChatGPT says, “Absolutely! I can help you find reliable sources, summarize information, organize your thoughts, and even suggest angles you might not have considered.” Google’s AI also promises to “streamline” the peer review process, especially “in the initial stages [by] automating tasks like identifying potential reviewers and summarizing research findings, potentially speeding up the review process.” [106] [107]
As a research partner, AI is helping in myriad ways. It’s speeding up drug discovery, analyzing huge quantities of particle accelerator data, automating repetitive tasks such as protein folding, making weather predictions, assessing bee behavior patterns, reviewing audio for bird and electric wire collisions, using game theory to catch animal poachers, evaluating social media posts to locate and track animals on the endangered list, predicting regions of poverty, and even identifying areas of city water pipes that need upgrades. In other words, AI is an enthusiastic and super-powered intern—ready to do the both grunt work as well as high-level thinking. [108] [109] [110]
Pro Quotes
Co-founder of LinkedIn Reid Hoffman stated:
I truly believe that by giving billions of people access to A.I. tools they can use in whatever ways they choose, we can create a world where A.I. augments and amplifies human creativity and labor instead of simply replacing it....
Tech skeptics have long used the adjective “Orwellian” to cast everything from a video recommendation feature to turn-by-turn navigation apps as threats to individual autonomy, but the history of technological innovation in the 21st century tells a different story. In “1984,” George Orwell’s classic novel of state oppression, powerful telescreens enable a totalitarian regime to rule over dispossessed proles with unchecked omnipotence. But today we live in a world where individual identity is the coin of the realm — where plumbers and presidents alike aspire to be social media influencers and cultural power flows increasingly to self-made operators.…
I believe A.I. is on a path not just to continue this trend of individual empowerment but also to dramatically enhance it. [97]
David Brooks , opinion columnist for The New York Times , stated:
I don’t think A.I. is going to be as powerful as many of its evangelists think it will be. I don’t think A.I. is ever going to be able to replace us — ultimately I think it will simply be a useful tool. In fact, I think instead of replacing us, A.I. will complement us. In fact, it may make us free to be more human.
Many fears about A.I. are based on an underestimation of the human mind. Some people seem to believe that the mind is like a computer. It’s all just information processing, algorithms all the way down, so of course machines are going to eventually overtake us.
This is an impoverished view of who we humans are.… The brain is its own universe. Sometimes I hear tech people saying they are building machines that think like people. Then I report this ambition to neuroscientists and their response is: That would be a neat trick, because we don’t know how people think. [101]
Medha Bankhwal, Michael Chui, Ankit Bisht, Roger Roberts, and Ashley van Heteren, all of consulting firm McKinsey & Company , stated:
By collaborating to find ways to put AI to work at scale for social good, mission-driven organizations, governments, foundations, universities, ecosystems of developers, and businesses can help solve some of the world’s most challenging and intractable problems. They can help thwart human trafficking, ensure girls and children all over the world receive the education they deserve, protect forests from illegal deforestation, support the health and safety of pregnant women and newborns, and so much more. If these things aren’t worth fighting for, what is? [102]
Con 1: AI is harming the economic well-being of many people and businesses.
AI robots and other software and hardware are becoming less expensive and need none of the benefits and services required by human workers, such as sick days, lunch hours, bathroom breaks, health insurance, pay raises, promotions, and performance reviews, which spells trouble for workers and society at large. [51]
Some 48 percent of experts believed AI will replace a large number of blue- and even white-collar jobs (including Hollywood and TV script writing), creating greater income inequality, increased unemployment, and a breakdown of the social order. [35]
The axiom “everything that can be automated, will be automated” is no longer science fiction. Self-checkout kiosks in stores like CVS, Target, and Walmart use AI-assisted video and scanners to prevent theft, alert staff to suspicious transactions, predict shopping trends, and mitigate sticking points at checkout. These AI-enabled machines have displaced human cashiers. About 11,000 retail jobs were lost in 2019, largely due to self-checkout and other technologies. In 2020, during the COVID-19 pandemic, a self-checkout manufacturer shipped 25 percent more units globally, reflecting the more than 70 percent of American grocery shoppers who preferred self- or touchless checkouts. [35] [52] [53] [54] [55]
An October 2020 World Economic Forum report found 43 percent of businesses surveyed planned to reduce workforces in favor of automation. Many businesses, especially fast-food restaurants, retail shops, and hotels, automated jobs during the COVID-19 pandemic. [35]
Income inequality was exacerbated over the last four decades as 50–70 percent of changes in American paychecks were caused by wage decreases for workers whose industries experienced rapid automation, including AI technologies. [56] [57]
AI is especially harming writers, publishers, and content creators. AI chatbots are being trained on online information (obtained through “web scraping” tools) that was professionally created at great expense by publishers, journalists, scholars, and authors, and this often happens without the latter’s permission or compensation to them. This is bad enough, but then the cannibalized content is summarized (often inaccurately, creating what’s called “hallucinations”) and offered for free to consumers as AI overviews (some of which are very detailed and as long as published articles) via search engines like Google, further harming the content creators by decreasing the consumer’s need to click on their sites. Critics have called this development the new “zero-click reality.” It’s a double assault on the publishing industry. [117] [118]
Con 2: AI undermines critical thinking skills for students and adults alike.
The idea that the Internet is making us stupid is legitimate, and AI is like the Internet on steroids.
With AI bots doing everything from research to writing papers, from basic math to logic problems, from generating hypotheses to performing science experiments, from editing photos to creating “original” art, students of all ages will be tempted (and many will succumb to the temptation) to use AI for their school work, undermining education goals. [82] [83] [84] [85] [86]
“The academic struggle for students is what pushes them to become better writers, thinkers and doers. Like most positive outcomes in life, the important part is the journey. Soon, getting college degrees without AI assistance will be as foreign to the next generation as payphones and Blockbuster [are to the current generation], and they will suffer for it,” says Mark Massaro, professor of English at Florida SouthWestern State College. [83]
A June 2023 study found that increased use of AI correlates with increased student laziness because of a loss of human decision-making. Similarly, an October 2023 study found not only increased laziness and carelessness but also a decline in work quality when humans worked alongside AI robots. [87] [88] [89]
The implications of allowing AI to complete tasks are enormous. We will see declines in work quality and human motivation as well as the rise of dangerous situations from deadly workplace accidents to George Orwell’s dreaded “ groupthink .” And, when humans have become too lazy to program the technology, we’ll see lazy AI, too. [90]
“An overreliance on technology will further sever the American public from determining truth from lies, information from propaganda, a critical skill that is slowly becoming a lost art, leaving the population willfully ignorant and intellectually lazy,” explains Massaro. [73] [83]
Con 3: AI hurts racial minorities by repeating and exacerbating racism.
Facial recognition has been found to be racially biased, easily recognizing the faces of white men while wrongly identifying Black women 35 percent of the time. One study of Amazon’s Rekognition AI program falsely matched 28 members of the U.S. Congress with mugshots from a criminal database, with 40 percent of the errors being people of color. [22] [36] [43] [44]
AI has also been disproportionately employed against Black and Brown communities, with more federal and local police surveillance cameras in neighborhoods of color, and more social media surveillance of Black Lives Matter and other Black activists. The same technologies are used for housing and employment decisions and TSA airport screenings. Some cities, including Boston and San Francisco, have banned police use of facial recognition for these reasons. [36] [43]
One particular AI software tasked with predicting recidivism risk for U.S. courts—the Correctional Offender Management Profiling for Alternative Sanctions (Compas)—–was found to falsely label Black defendants as high risk at twice the rate of white defenders, and to falsely label white defendants as low risk more often. AI is also incapable of assessing nuance, such as distinguishing between when the N-word is being used as a slur and when it’s being used culturally by a Black person. [45] [46]
In China, facial recognition AI has been used to track Uyghurs, a largely Muslim minority. The U.S. and other governments have accused the Chinese government of genocide and forced labor in Xinjiang, where a large population of Uyghurs live. AI algorithms have also been found to show a “persistent anti-Muslim bias,” by associating violence with the word “Muslim” at a higher rate than with words describing people of other religions including Christians, Jews, Sikhs, and Buddhists. [47] [48] [50]
Con 4: Artificial intelligence poses dangerous privacy risks.
Facial recognition technology can be used for passive, warrantless surveillance without the knowledge of the person being watched. In Russia, facial recognition was used to monitor and arrest protesters who supported jailed opposition politician Aleksey Navalny , who was found dead in prison in 2024. Russians fear a new facial recognition payment system for Moscow’s metro will increase these sorts of arrests. [36] [37] [38]
Ring, the AI doorbell and camera company owned by Amazon, has partnered with more than 400 police departments, allowing the police to request footage from users’ doorbell cameras. While users were allowed to deny access to any footage, privacy experts feared the close relationship between Ring and the police could override customer privacy, especially when the cameras frequently record activity on others’ property. The policy ended in 2024, but experts say other companies allow similar invasions. [39] [91]
AI also follows you on your weekly errands. Target used an algorithm to determine which shoppers were pregnant and sent them baby- and pregnancy-specific coupons in the mail, infringing on the medical privacy of those who may be pregnant, as well as those whose shopping patterns may just imitate pregnant people. [40] [41]
Moreover, artificial intelligence can be a godsend to crooks. In 2020 a group of 17 criminals defrauded $35 million from a bank in the United Arab Emirates using AI “deep voice” technology to impersonate an employee authorized to make money transfers. In 2019, thieves attempted to steal $240,000 using the same AI technology to impersonate the CEO of an energy firm in the United Kingdom. [42]
Con 5: AI can spread politicized, even dangerous misinformation.
“The ability to create websites that host fake news or fake information has been around since the inception of the Internet, and they pre-date the AI revolution,” according to engineering and machine learning expert Walid Saad. “With the advent of AI, it became easier to sift through large amounts of information and create ‘believable’ stories and articles. Specifically, LLMs [large language models] made it more accessible for bad actors to generate what appears to be accurate information. This AI-assisted refinement of how the information is presented makes such fake sites more dangerous." [111]
A 2024 study noted highlights of the AI misinformation problem: “With the advent of generative artificial intelligence (AI), the internet has become a breeding ground for fake news and misinformation. The phenomenon of fake news and misinformation has had significant impacts across various sectors, including the world of finance and politics. A notable example occurred in mid-January 2023, when the spread of a false report stating that the SEC (U.S. Securities and Exchange Commission) had approved a spot-listed ETF (exchange-traded fund) caused volatility in Bitcoin prices. In May 2023, an instance of generative AI being used to create a fictitious image of a building near the Pentagon in Washington D.C. engulfed in black flames, leading to turmoil in the U.S. stock market. Additionally, fabricated images of a former U.S. president being arrested and a fashionably dressed Pope in a white puffer coat were examples of fake news created using AI-generated fake photographs.” [112]
Google’s AI chatbot Gemini even generated historical inaccuracies by inserting people of color into historical events they never participated in—including Black Nazi soldiers and Black Popes—further damaging historical literacy. [73]
AI can also be politicized by both AI creators and AI users. A May 2023 study by the Brookings Institute found that the AI knowledge source routinely supported left-leaning positions on hot button issues including abortion and gun control, while AI robocalls were banned by the FCC for imitating President Joe Biden’s voice during the 2024 election. In 2025, political operatives broadcast a lewd AI-generated video of President Trump and Elon Musk on all Department of Housing and Urban Development (HUD) headquarter monitors. [75] [76] [77] [92] [113]
Equally troubling, as exemplified by robocalls and deep-fake videos, AI can be virtually indistinguishable from humans. Impressionable people can be swayed into harmful actions including but not limited to eating disorders, suicide, and assassination. For example, a British man was arrested in a plot to kill Queen Elizabeth in 2021 after a chatbot encouraged him to do so, saying his assassination plan was “very wise.” AI bots have also created and publicized potentially deadly recipes and recommended harmful solutions to losing weight. In 2025, it was reported that ChatGPT suggested a man replace table salt with sodium bromide, a substance used to treat outdoor pool water, which resulted in bromism (sodium bromide poisoning) that manifests as paranoia and hallucinations as well as an electrolyte imbalance, among other symptoms. He recovered after weeks in the hospital that included an involuntary psychiatric hold. [114] [115] [116] [119]
Marjorie Wallace, founder and chief executive of mental health charity SANE, says “the rapid rise of artificial intelligence has a new and concerning impact on people who suffer from depression, delusions, loneliness and other mental health conditions.” As the technology becomes more and more indistinguishable from reality, we will all need to be vigilant about and protected from the dangerous uses of AI. [116]