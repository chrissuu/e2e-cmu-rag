Table of Contents Ask the Chatbot
Top Questions
A deepfake is synthetic media generated by artificial intelligence (AI) technology. It portrays events or things that do not exist in reality. The term combines deep from AI deep-learning technology (a type of machine learning that involves multiple levels of processing) and fake because the subject of the depiction did not actually occur.
How are deepfakes created?
How are deepfakes created?
Deepfakes are often made using generative adversarial networks (GANs), in which two AI models work together to create realistic replicas. One of the models creates the best possible replica of a real image or video, and the other detects whether the replica is fake and, if it is, reports on the differences between it and the original. Deepfakes can also be generated by diffusion models that create images from text prompts.
deepfake , synthetic media, including images, videos, or audio, generated by artificial intelligence (AI) technology that portray something that does not exist in reality or events that have never occurred.
The term deepfake combines deep , taken from AI deep-learning technology (a type of machine learning that involves multiple levels of processing), and fake , addressing that the content is not real. The term came to be used for synthetic media in 2017 when a Reddit moderator created a subreddit called “r/deepfakes” and began posting videos that used face-swapping technology to insert celebrities’ likenesses into existing pornographic videos.
How deepfakes are made
Deepfakes are often produced using generative adversarial networks (GANs), in which two different AI deep-learning models work together in a guessing game. One of the models creates the best possible replica of a real image or video and the other detects whether the replica is fake and, if it detects an error, reports on the differences between it and the original. In other words the first algorithm produces a synthetic image and receives feedback on its creation from the second model and then adjusts it to make it appear more real; the process is repeated as many times as it takes until the second model does not detect any false imagery.
Deepfakes may also be generated by diffusion models . In this method a text prompt generates a visual representation of a concept, which is inundated with noise, or random data values. The model then learns to create high-quality images by gradually removing the noise and generating an accurate visualization of the text prompt. As programs such as Stable Diffusion and Midjourney have grown more advanced in the mid-2020s, so too has their capacity to create convincing deepfakes.
In deepfake videos, a specific person’s voice may be replicated by feeding an AI model real audio data from the person, thereby training it to mimic them. Oftentimes, deepfake videos are produced by overdubbing existing footage of a person speaking with new AI-generated audio mimicking the voice of that person.
Dangers
Deepfakes are, more often than not, associated with nefarious motives, including creating disinformation and generating confusion about politically important matters. They have been used to demean, intimidate, and harass and have targeted not only celebrities, politicians, and CEOs, but ordinary citizens as well. One way to improve the ability to spot deepfakes is to have an understanding of news literacy .
A report by the cybersecurity company McAfee showed that more than 500,000 deepfakes had been shared on social media in 2023. The use of deepfakes has become increasingly common in scams involving impersonation. In one widely reported case an employee working for the engineering firm Arup transferred about $25 million to bad actors after participating in a virtual call featuring deepfakes of Arup’s CFO and other employees. Deepfake scams have also increasingly been used in online dating. Scammers video-call their victims using swapped likenesses to orchestrate money transfers. The Federal Bureau of Investigation reported that upwards of $650 million was lost in such “romance fraud” schemes in 2023.
A 2019 report by Sensity AI found that about 96 percent of deepfakes are nonconsensual sexual images, and nearly all of those images are of women.
An increasingly prevalent problem with deepfakes is their role in creating and circulating nonconsensual pornography . According to a 2019 report by Sensity AI, about 96 percent of deepfakes are nonconsensual sexual images, and nearly all of those images feature women. In January 2024 American singer-songwriter Taylor Swift was targeted in explicit images on X (formerly Twitter). The manufactured images were widely circulated across the Internet and led to outrage regarding the lack of deepfake legislation in the United States . The first such law was signed into existence by U.S. Pres. Donald Trump in May 2025; the TAKE IT DOWN Act criminalizes the publication and distribution of sexually explicit images (either computer-generated or otherwise) without the participant’s consent.
In addition to pornography, examples of deepfakes that have been widely circulated include an image of Pope Francis in a puffer jacket, an image of Trump in a scuffle with police, a video of Facebook CEO Mark Zuckerberg giving a speech about his company’s nefarious power, and a video of Queen Elizabeth dancing and giving a speech about the power of technology. None of these events occurred in real life.
In a disturbing online trend that started about the end of 2023, child murder victims’ likenesses (created using deepfake technology) appeared on platforms such as TikTok to narrate the stories of how they were killed. This was often done without the consent of the children’s families, many of whom expressed disgust at the exploitation of their tragedy for views.
Positive uses
Some positive uses for deepfakes have also emerged, however. One is spreading awareness about social issues. For example, soccer player David Beckham participated in a campaign to increase awareness about malaria in which videos were produced that appeared to show him speaking in nine different languages, broadening the reach of the message. The art world has also found positive uses for deepfake technology. An exhibition called “Dalí Lives” at the Dalí Museum in St. Petersburg, Florida, featured a life-size video display of the artist Salvador Dalí delivering quotes from his interviews and written correspondence in a voice that mimicked his. Several humorous deepfakes have emerged as well. One TikTok account is entirely dedicated to deepfakes of Keanu Reeves , with videos ranging from humorous takes on romantic relationships to TikTok dances.
With families’ consent, deepfake technology has been used to create compelling portrayals of deceased individuals to raise awareness about the circumstances that led to their death. After 18-year-old U.K. rapper Joshua Ribera was stabbed to death in 2013, his family approved for his likeness to be used as part of an anti-knife campaign. A music video featuring Depzman (as Ribera was known) was created in 2022 with deepfake technology and helped to educate viewers about the dangers of knife violence. In the Netflix documentary American Murder: Gabby Petito (2025), murder victim Gabby Petito’s text messages and letters are seemingly narrated with her voice using deepfake technology. Although Netflix had received permission from Petito’s family to recreate her voice, the decision was controversial, and some critics called it disrespectful to Petito’s memory.
Education and medicine are two additional fields that may benefit from deepfake technology. In the classroom, educators may use deepfakes of historical speeches to offer immersive and engaging lessons. Using deepfake technology in health care can improve the accuracy with which tumors are spotted on magnetic resonance imaging (MRI) scans, making them easier to treat. For example, because tumors or abnormalities are relatively rare in the general population, it is difficult to have enough images of them with which to train an AI program for diagnostic purposes. Deepfake images allow such AI programs to be trained to recognize a greater number of abnormalities, hence improving their long-term accuracy. Their use also permits research to be conducted using synthesized data instead of data from real patients, enabling researchers to avoid privacy concerns.