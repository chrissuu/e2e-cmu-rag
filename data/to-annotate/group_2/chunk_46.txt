machines that see. As a scientific discipline, computer vision is concerned with the
theory behind artificial systems that extract information from images. The image data
can take many forms, such as video sequences and views from cameras. In most practical
computer vision applications, the computers are pre-programmed to solve a particular
task, but methods based on learning are now becoming increasingly common. Computer
vision systems rely on image sensors that detect electromagnetic radiation which is
typically in the form of either visible light or infra-red light. The sensors are
designed using solid-state physics. The process by which light propagates and reflects
off surfaces is explained using optics. Sophisticated image sensors even require quantum
mechanics to provide a complete understanding of the image formation process. Robots
can also be equipped with multiple vision sensors to be better able to compute the
sense of depth in the environment. Like human eyes, robots' "eyes" must also be able
to focus on a particular area of interest, and also adjust to variations in light
intensities. There is a subfield within computer vision where artificial systems are
designed to mimic the processing and behavior of biological system, at different levels
of complexity. Also, some of the learning-based methods developed within computer
vision have a background in biology. Though a significant percentage of robots in
commission today are either human controlled or operate in a static environment, there
is an increasing interest in robots that can operate autonomously in a dynamic environment.
These robots require some combination of navigation hardware and software in order
to traverse their environment. In particular, unforeseen events (e. g. people and
other obstacles that are not stationary) can cause problems or collisions. Some highly
advanced robots such as ASIMO and Mein√º robot have particularly good robot navigation
hardware and software. Also, self-controlled cars, Ernst Dickmanns' driverless car,
and the entries in the DARPA Grand Challenge, are capable of sensing the environment
well and subsequently making navigational decisions based on this information, including
by a swarm of autonomous robots. [119] Most of these robots employ a GPS navigation
device with waypoints, along with radar, sometimes combined with other sensory data
such as lidar, video cameras, and inertial guidance systems for better navigation
between waypoints. The state of the art in sensory intelligence for robots will have
to progress through several orders of magnitude if we want the robots working in our
homes to go beyond vacuum-cleaning the floors. If robots are to work effectively in
homes and other non-industrial environments, the way they are instructed to perform
their jobs, and especially how they will be told to stop will be of critical importance.
The people who interact with them may have little or no training in robotics, and
so any interface will need to be extremely intuitive. Science fiction authors also
typically assume that robots will eventually be capable of communicating with humans
through speech, gestures, and facial expressions, rather than a command-line interface.